---
title: "Invariance Testing"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
    number_sections: true
editor_options:
  chunk_output_type: console
---



# Set-up


```{r, message = FALSE}
library('gets')

knitr::opts_chunk$set(comment = "")

# Set seed
set.seed(123)

# Number of observations
n <- 100
```

# Function definition
```{r}
parameter_invariance <- function(model){
  if(nrow(as.data.frame(model$coefficients))>=4) {
    
    b <- as.numeric(t(model$coefficients[-(1:3)]))
    fstat <- b %*% as.matrix(solve(vcov(model)[-c(1:3), -c(1:3)])) %*% t(t(b))/2
    fstat_pvalue <- pf(fstat,
                       df1 = nrow(as.data.frame(model$coefficients[-c(1:3)])),
                       df2 = nrow(as.data.frame(model$coefficients)) - nrow(as.data.frame(model$coefficients[-c(1:3)])),
                       lower.tail = FALSE)
    
    chisq_pvalue <- 1 - pchisq(fstat*2, nrow(as.data.frame(model$coefficients[-c(1:3)])))
    
    
    
    cat("Super exogneity test (Null hyphothesis is parameter invariance):","\n")
    cat("F-statistic:", fstat, "\n")
    cat("F-distribution p-value:", fstat_pvalue, "\n")
    cat("Chi-2 Distribution p-value:", chisq_pvalue, "\n")
    
  } else {
    
    cat("No Outliers detected","\n")
  }
  
  
  # htest <- list(
  #   statistic = fstat,
  #   p.value = fstat_pvalue,
  #   estimate = cf_diff,
  #   null.value = NULL,
  #   df = rel.df,
  #   alternative = "Parameters are variant.",
  #   method = "Super Exogeneity (Parameter Invariance) Test",
  # )
  # attr(rval_chi, "class") <- c("htest")
  # out <- return(rval_chi)
  
  
}


```



# Generate Data

Generate exogenous variables with outliers or breaks in them. In this instance, we only introduce outliers in the exogenous variables.


```{r}
x <- c(rnorm(n/2),25,rnorm(n/2-1))
w <- c(rnorm(n/4),25,rnorm(3*n/4-1))

# Generate residuals
error <- rnorm(n)

# Generate conditional model
y <- 2*x  + 3*w + 1 + error
```


# Case 1 (parameter invariance)


Then we run ISAT on the exogenous variables.


```{r}
# Create a data frame
data <- data.frame(w = w, x = x, y = y)

# search for outliers in exogenous variables and add them to dataset
xsat <- isat(data$x, iis=TRUE, sis=FALSE, plot=TRUE , t.pval = 1/n, print.searchinfo = FALSE)$aux$mX
wsat <- isat(data$w, iis=TRUE, sis=FALSE, plot=TRUE , t.pval = 1/n, print.searchinfo = FALSE)$aux$mX
```

If we find an outlier in the exogenous variable, we add this to the model where x and w are explanatory variables (the conditional model).

```{r}
datax <- cbind(data,xsat,wsat)
datax <- datax[, -which(names(datax) %in% c("mconst","mconst.1"))]

# note probably need something here to drop duplicates.
# Also need to be careful not to test outliers if already included in the conditional model
```

Now we estimate a conditional model with any added outliers and test their significance.


```{r}
model <- lm(y ~ ., data = datax)
summary(model)
```

In the conditional model, these outliers are then insignificant. This, in my interpretation is essentially expressing that the coefficients of the model is fixed with respect to the outliers? In other words, because the coefficients are fixed (and we know how we create the y variable), y is going to respect the outlier dynamics that are contained within w and x. 


Then we run the parameter invariance test: 
```{r}
parameter_invariance(model)
```

This is why the Null hypothesis of fixed coefficients/invariant parameters is not rejected, so we conclude that the model parameters are invariant.


# Case 2 (parameter variance)

In Case 2, we counteract the outliers in w and z in the creation of y. When we use those two lines, what is happening is that when constructing y, the outlier dynamics in x and w do not have an influence in y i.e. we reverse the effect of the outliers back to the original relationship.

```{r}
# Uncomment here to allow for parameter invariance so that test rejects
y_c2 <- y
y_c2[26] <- 2*x[26]  + 0.03*w[26] + 1 + error[26]
y_c2[51] <- 0.02*x[51]  + 3*w[51] + 1 + error[51]
```

This, in a way, expresses that for those two observations, the coefficient must have changed (i.e. the parameters must be variant)– otherwise there is no way y would have those values with those outliers in x and w. *Is this the correct interpretation?*

We then run everything as per usual:


```{r}
# Create a data frame
data_c2 <- data.frame(w = w, x = x, y = y_c2)
datax_c2 <- cbind(data_c2,xsat,wsat)
datax_c2 <- datax_c2[, -which(names(datax_c2) %in% c("mconst","mconst.1"))]

# note probably need something here to drop duplicates.
# Also need to be careful not to test outliers if already included in the conditional model

# Estimate conditional model with any added outliers and test their significance
model_c2 <- lm(y ~ ., data = datax_c2)
summary(model_c2)
```
Different to above, we now see that some outliers are significant. 

When we run the parameter invariance test, we see that this now rejects. 

```{r}
parameter_invariance(model_c2)
```




# Straying further: running isat on the conditional model

So you clearly say that we should not run IIS on the conditional model anymore before running the test. I'm trying to figure out what implications that could have in OSEM, so indulge me for a minute trying out a few things.


## isat on the conditional model: Case 1

Do you mean just a univariate isat model on y? I would guess not, but when I run this, I get the two outliers again. 

```{r}
isat(data$y, iis=TRUE, sis=FALSE, plot=TRUE , t.pval = 1/n, print.searchinfo = FALSE)
```


But let's focus on what makes more sense, the conditional model with x and w as covariates. 

If I do the conditional model with covariates in CASE 1 (the parameter invariant one), then *I do not detect any further outliers* – as would be expected because y follows perfectly from x and w (i.e. we recover the original model). 

**Hence the parameter invariance test result would also not change.**

```{r}
isat(data$y,mxreg = cbind(x,w), iis=TRUE, sis=FALSE, plot=TRUE , t.pval = 1/n, print.searchinfo = FALSE)
```

## isat on the conditional model: Case 2

So the more interesting model yet again would be case 2 (the parameter variant case).

### Ignoring the results from the exogenous models before

Let's run this first without adding any results form running the models on `x` and `w`. 

```{r}
isat(data_c2$y,mxreg = cbind(x,w), iis=TRUE, sis=FALSE, plot=TRUE , t.pval = 1/n, print.searchinfo = FALSE)
```

Here I perfectly detect the outliers in the positions that I would have expected them. Indeed, those are the same two outliers that I would have added manually from the models on the exogenous variables. 


### Using the results from the exogenous models before

But let's consider that we are using the analyses on the exogenous variables. 


```{r}
isat(datax_c2$y,mxreg = datax_c2[,!names(datax_c2) == "y"], iis=TRUE, sis=FALSE, 
     plot=TRUE , t.pval = 1/n, print.searchinfo = FALSE)
```

**I then do not identify any further outliers**. Therefore this also gives me exactly the same result as before. 

## Case 3 on Case 1: Now also adding an outlier in y (that is not caused by x or w)

In practice, I would expect us finding also outliers that are not determined by outliers in exogenous variables. Let's for example assume that there is an additional outlier in y. 

In this case, we base it on the parameter variant case 1:

```{r}
y_c31 <- y
y_c31[87] <- -10
```

Now we do the same thing as in Case 2:

```{r}
# Create a data frame
data_c31 <- data.frame(w = w, x = x, y = y_c31)
datax_c31 <- cbind(data_c31,xsat,wsat)
datax_c31 <- datax_c31[, -which(names(datax_c31) %in% c("mconst","mconst.1"))]

# note probably need something here to drop duplicates.
# Also need to be careful not to test outliers if already included in the conditional model

# Estimate conditional model with any added outliers and test their significance
arx(y = datax_c31$y, mxreg = datax_c31[!names(datax_c31) == "y"], plot = TRUE)
model_c31 <- lm(y ~ ., data = datax_c31)
```

Let's now also run the test on this: 

```{r}
parameter_invariance(model = model_c31)
```

This **does not reject**, which is **correct** for the exogenous variables - but do we want this to be true when we have a remaining outlier in y?

### Ignoring the exogenous analyses

When not using the information from the exogenous relationships, we get everything we are looking for (no outliers in y that were already in x or w but an additional outlier for `iis87`):

```{r}
(is_c31 <- isat(data_c31$y,mxreg = cbind(x,w), iis=TRUE, sis=FALSE, plot=TRUE , t.pval = 1/n,
                print.searchinfo = FALSE))
```
**But now the test rejects, which is incorrect**:

```{r}
parameter_invariance(is_c31)
```

So the running of isat on the conditional model without adding the outliers from the exogenous equations would distort the Super exogeneity test. 


### Now using the exogenous analyses

But let's try to use isat on the conditional model again because as the plot above shows, there is clearly an outlier in y and it would be great to deal with it. 

```{r}
(is_c31_exog <- isat(datax_c31$y,mxreg = datax_c31[,!names(datax_c31) == "y"], iis=TRUE, sis=FALSE, 
                     plot=TRUE , t.pval = 1/n,
                     print.searchinfo = FALSE))
```

Then here we find the additional outlier at position 87 - but of course retain all outliers that were in the exogenous relationships.

Let's run the test once more:

```{r}
parameter_invariance(is_c31_exog)
```

**This also rejects**! Which is not correct!



## Case 3 on Case 2: Now also adding an outlier in y (that is not caused by x or w)

In practice, I would expect us finding also outliers that are not determined by outliers in exogenous variables. Let's for example assume that there is an additional outlier in y. 

In this case, we base it on the parameter variant case 2:

```{r}
y_c32 <- y_c2
y_c32[87] <- -10
```

Now we do the same thing as in Case 2:

```{r}
# Create a data frame
data_c32 <- data.frame(w = w, x = x, y = y_c32)
datax_c32 <- cbind(data_c32,xsat,wsat)
datax_c32 <- datax_c32[, -which(names(datax_c32) %in% c("mconst","mconst.1"))]

# note probably need something here to drop duplicates.
# Also need to be careful not to test outliers if already included in the conditional model

# Estimate conditional model with any added outliers and test their significance
arx(y = datax_c32$y, mxreg = datax_c32[!names(datax_c32) == "y"], plot = TRUE)
model_c32 <- lm(y ~ ., data = datax_c32)
```

Let's now also run the test on this: 

```{r}
parameter_invariance(model = model_c32)
```

This still rejects, which is **correct**. 

### Ignoring the exogenous analyses

When not using the information from the exogenous relationships, we get everything we are looking for:

```{r}
(is_c32 <- isat(data_c32$y,mxreg = cbind(x,w), iis=TRUE, sis=FALSE, plot=TRUE , t.pval = 1/n, 
                print.searchinfo = FALSE))
```

```{r}
parameter_invariance(is_c32)
```



### Now using the exogenous analyses

But let's try to use isat on the conditional model again because as the plot above shows, there is clearly an outlier in y and it would be great to deal with it. 

```{r}
(is_c32_exog <- isat(datax_c32$y,mxreg = datax_c32[,!names(datax_c32) == "y"], iis=TRUE, sis=FALSE, 
                     plot=TRUE , t.pval = 1/n, print.searchinfo = FALSE))
```

Then here we find the additional outlier at position 87 - but of course retain all outliers that were in the exogenous relationships (so the difference to above is `iis73`).


```{r}
parameter_invariance(is_c32_exog)
```


## Conclusion on running isat on the conditional model

So as Andrew has said: running isat on the conditional model is a bad idea - because identifying a true outlier in the conditional model will distort the super exogeneity test by overrejecting.  


# Open Questions: 

- Given the analysis on running isat on the conditional model above, should we just ignore any outliers in y that were not caused by x or w (at least for the super exogeneity test)?
--> Yes

- Do we have a clear reference for the test when I implement it now? Obviously Engle et al 1983, but anything more recent? I think there was a paper by David around 2010, no? 

- Which p-value would we need to look at? F-stat or Chi-sq?
--> Use the F-test but I will try to report both

- What would our result/statement be if we do not identify any indicators in the model on the exogenous variable(s)?
--> Cannot perform the test (no outliers detected, unable to test for invariance)

- we always run ISAT on the exogenous variables in a univariate way, right? Could we be more elaborate in that (with more AR terms or trends)? My understanding would be yes, correct?  


# Potential implementation in OSEM

What do you think?

Current structure of OSEM:

1. Using `isat`, estimate each module (i.e. for each y variable) e.g. 5 times with AR 0 to AR 1-4, depending on specification with e.g. IIS activated
2. Out of those, we choose a model with BIC
3. Depending on setting, we then run gets on the best BIC model for the non-trend/IIS/SIS variables
4. Run isat on the final gets model again to give us the final model


Given all this, my thinking goes into the following direction: 

1. Using `isat`, estimate each module (i.e. for each y variable) e.g. 5 times with AR 0 to AR 1-4, depending on specification with e.g. IIS activated
2. Out of those, we choose a model with BIC
3. Depending on setting, we then run gets on the best BIC model, giving us the final model
4. For the final model, we run for each exogenous variable a sub-model with isat to identify any outliers in the exogenous variables
5. Using these outliers from the exogenous variables, we run an OLS with the covariate structure of the final model from step 3 but 
- without any outliers identified in Step 1
- but with all outliers identified in Step 4



$$y_t = \beta x_t + \beta x_{t-1} + \varepsilon$$

$$x_t = x_{t-1} + IIS_5 + SIS_{10}$$
$$y_t = \beta x_t + \beta x_{t-1} + IIS_5 + SIS_{10} + \varepsilon$$
